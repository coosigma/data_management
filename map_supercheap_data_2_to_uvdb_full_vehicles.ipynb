{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Defining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cached_tables = 1\n",
    "use_cached_data = 1\n",
    "use_cached_engine_scores = 1\n",
    "use_cached_vehicle_scores = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_features = {'make': 'make_id', 'model': 'model_id', 'year_from': 'from', 'year_to': 'to', \n",
    "                    'model_code': 'uvdb_model_codes.id','body': 'body_type_id', 'drive': 'drive_type_id',\n",
    "                    'engine': 'defined_engine_id'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "supercheap_vehicle_features = ['make', 'year', 'model', 'model_code', 'body', 'drive_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_features = {'capacity': 'cc', 'designation': 'uvdb_defined_engine_designations.engine_designation_id',\n",
    "                   'block': 'block_type', 'cylinders': 'cylinders', 'valves': 'valves_id',\n",
    "                   'head': 'cylinder_head_type_id', 'aspiration': 'aspiration_id', 'delivery': 'fuel_delivery_subtype_id',\n",
    "                   'power': 'power_output_id'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_feature_types = {'capacity': 'float', 'cylinders': 'int', 'valves': 'int', 'power': 'float', 'delivery': 'string'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_feature_types = {'make': 'string', 'year': 'int', 'from': 'int', 'to': 'int', 'model': 'string', 'model_code': 'string',\n",
    "                        'body': 'string', 'drive_id': 'int', 'defined_engine_id': 'string'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from sqlalchemy import create_engine\n",
    "from Levenshtein import distance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numba as nb\n",
    "import scipy as sp\n",
    "import pymysql, time, re, math, pickle, h5py, os\n",
    "from scipy.sparse import csr_matrix\n",
    "from IPython.core.debugger import Tracer\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_tools import data_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'user': 'staging',\n",
    "    'passwd': '$dsaGSD92&76',\n",
    "    'host': '10.106.48.3',\n",
    "    'port': '3306',\n",
    "    'dbs': [\"ebay.supercheap_data_2\", \"partly_staging\"],\n",
    "    'readdb': use_cached_tables ^ 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = data_tools(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5572447776794434\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "if use_cached_tables == 1:\n",
    "    with open('Data/table_cache.dat', 'rb') as fh:\n",
    "        df = pickle.load(fh)\n",
    "else:\n",
    "    df = tools.read_df_from_table()\n",
    "    with open('Data/table_cache.dat', 'wb') as fh:\n",
    "        pickle.dump(df, fh) \n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2353827953338623\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "if use_cached_data == 1:\n",
    "    with open('Data/data_cache.dat', 'rb') as fh:\n",
    "        data = pickle.load(fh)\n",
    "else:\n",
    "    data = tools.transform_data_from_tables(df, vehicle_features, supercheap_vehicle_features, engine_features)\n",
    "    with open('Data/data_cache.dat', 'wb') as fh:\n",
    "        pickle.dump(data, fh) \n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_factors = {\n",
    "    'designation': 20,\n",
    "    'capacity': 9, \n",
    "    'power': 3, \n",
    "    'block': 9, \n",
    "    'cylinders': 10, \n",
    "    'valves': 8, \n",
    "    'head': 9, \n",
    "    'aspiration': 6, \n",
    "    'delivery': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_factors = {\n",
    "    'make': 3,\n",
    "    'year': 7,\n",
    "    'model': 10,\n",
    "    'model_code': 12,\n",
    "    'body': 7,\n",
    "    'drive': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_data(data, start, end, white_list):\n",
    "    res = {}\n",
    "    for key, df in data.items():\n",
    "        if key in white_list:\n",
    "            res[key] = df[start:end]\n",
    "        else:\n",
    "            res[key] = df[:]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_one_batch(start, end, full_data, engine_factors, vehicle_factors):\n",
    "    top_scores = {}\n",
    "    size = end - start\n",
    "    # Getting a batch of data\n",
    "    data = get_batch_data(full_data, start, end, ['super_vehicle', 'super_engine'])\n",
    "    # Calculating engnies scores\n",
    "    t0 = time.time()\n",
    "    if use_cached_engine_scores == 1:\n",
    "        with open(f'Data/engine_scores_{start}_{end}.dat', 'rb') as fh:\n",
    "            engine_scores = pickle.load(fh)\n",
    "    else:\n",
    "        engine_scores = tools.calculate_engine_scores(data, size, engine_feature_types)\n",
    "        with open(f'Data/engine_scores_{start}_{end}.dat', 'wb') as fh:\n",
    "            pickle.dump(engine_scores, fh)\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(f\"engine: {total}\")\n",
    "    \n",
    "    # Aggregating engine scores\n",
    "    engine_score = None\n",
    "    for key, value in engine_factors.items():\n",
    "        if engine_score is None:\n",
    "            engine_score = engine_scores[key] * value\n",
    "        else:\n",
    "            engine_score += engine_scores[key] * value\n",
    "            \n",
    "    # Getting Top 5 of engine scores\n",
    "    top_scores['engine'] = tools.get_top_k(engine_score, 5, data['super_engine'], data['defined_engine'])\n",
    "    \n",
    "    # Adding engine infomation to supercheap vehicle\n",
    "    data['super_vehicle'] = tools.add_engine_info(top_scores['engine'], data['super_vehicle'])\n",
    "    \n",
    "    # Calculating scores for vehicles\n",
    "    t0 = time.time()\n",
    "    if use_cached_vehicle_scores == 1:\n",
    "        with open(f'Data/vehicle_scores_{start}_{end}.dat', 'rb') as fh:\n",
    "            vehicle_scores = pickle.load(fh)\n",
    "    else:\n",
    "        vehicle_scores = tools.calculate_vehicle_scores(data, size, vehicle_feature_types)\n",
    "        with open(f'Data/vehicle_scores_{start}_{end}.dat', 'wb') as fh:\n",
    "            pickle.dump(vehicle_scores, fh) \n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(f\"vehicle engine: {total}\")\n",
    "    \n",
    "    # Aggregating vehicle scores\n",
    "    vehicle_score = None\n",
    "    for key, value in vehicle_factors.items():\n",
    "        if vehicle_score is None:\n",
    "            vehicle_score = vehicle_scores[key] * value\n",
    "        else:\n",
    "            vehicle_score += vehicle_scores[key] * value\n",
    "            \n",
    "    ## Getting top 5 of vehicle mapping\n",
    "    top_scores['vehicle'] = tools.get_top_k(vehicle_score, 5, data['super_vehicle'], data['full_vehicle'])\n",
    "    \n",
    "    return top_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0 : 5\n",
      "0.6702170372009277\n",
      "cal engine: 0.674724817276001\n",
      "1.5322656631469727\n",
      "vehicle engine: 1.5369303226470947\n",
      "processing 5 : 10\n",
      "0.6581687927246094\n",
      "cal engine: 0.6608150005340576\n",
      "1.5108158588409424\n",
      "vehicle engine: 1.5151381492614746\n",
      "processing 10 : 13\n",
      "0.39811158180236816\n",
      "cal engine: 0.39987826347351074\n",
      "0.9407675266265869\n",
      "vehicle engine: 0.9432008266448975\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "path = './Data/csr_matrix.h5'\n",
    "if os.path.isfile(path):\n",
    "    os.remove(path)\n",
    "full_size = data['super_vehicle'].shape[0]\n",
    "full_size = 20\n",
    "batch_size = 1e3\n",
    "batch_size = 5\n",
    "ascii_type = h5py.string_dtype('ascii', 70)\n",
    "with h5py.File(path, \"a\") as f: \n",
    "    engine_scores_dset = f.create_dataset('engine_scores', (full_size, 2), maxshape=(None, 2), \n",
    "          dtype=ascii_type, chunks=(batch_size, 2))\n",
    "    vehicle_scores_dset = f.create_dataset('vehicle_scores', (full_size, 2), maxshape=(None, 2), \n",
    "          dtype=ascii_type, chunks=(batch_size, 2)) \n",
    "\n",
    "    batch_cursor = 0\n",
    "    while batch_cursor < full_size:\n",
    "        start = int(batch_cursor)\n",
    "        end = int(batch_cursor + batch_size)\n",
    "        if end > full_size:\n",
    "            end = full_size\n",
    "        print(f\"processing {start} : {end}\")\n",
    "        each_result = calculate_one_batch(start, end, data, engine_factors, vehicle_factors)\n",
    "        # Append data here\n",
    "        engine_scores_dset[start: end] = each_result['engine'].astype(ascii_type)\n",
    "        vehicle_scores_dset[start: end] = each_result['vehicle'].astype(ascii_type)\n",
    "        batch_cursor = end\n",
    "pd.options.mode.chained_assignment = 'warn'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
